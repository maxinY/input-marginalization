{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"cnn-sst2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2838ab9232384653a9814f6462aa9338":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a889299762df48818c9920d797fbfadf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_07dd493912cf4f7f9a4f8b70b1d153a1","IPY_MODEL_d7f04a0011ef408499153e1329cc8099"]}},"a889299762df48818c9920d797fbfadf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"07dd493912cf4f7f9a4f8b70b1d153a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_79b58d6a92be4d2282dcf2e2a2be7923","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ebb62285bcd440c6b3995c9f969f6bdd"}},"d7f04a0011ef408499153e1329cc8099":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_938c65ebb461441d8d7a79d9da76b645","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 3.24MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e6cb0cb2464d4b0495a50618ce71b5b1"}},"79b58d6a92be4d2282dcf2e2a2be7923":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ebb62285bcd440c6b3995c9f969f6bdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"938c65ebb461441d8d7a79d9da76b645":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e6cb0cb2464d4b0495a50618ce71b5b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"n5UIHIwjbXUU","executionInfo":{"status":"ok","timestamp":1615900009277,"user_tz":240,"elapsed":382,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}}},"source":["%%capture\n","!git clone https://github.com/ronakdm/input-marginalization.git"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_AXX1JWiVpH","executionInfo":{"status":"ok","timestamp":1615900012072,"user_tz":240,"elapsed":526,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}},"outputId":"4cb326a0-369a-4da9-bdfb-5d5c52f9a494"},"source":["%%bash\r\n","cd input-marginalization\r\n","git pull\r\n","cd .."],"execution_count":3,"outputs":[{"output_type":"stream","text":["Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mdt1j3SUihdj","executionInfo":{"status":"ok","timestamp":1615900030845,"user_tz":240,"elapsed":17466,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}},"outputId":"c3a8323c-0caa-48db-e40f-7ae5102f7339"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n","save_dir = \"/content/gdrive/My Drive/input-marginalization\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0ff8o_N7KjOa","executionInfo":{"status":"ok","timestamp":1615900034566,"user_tz":240,"elapsed":5690,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}}},"source":["import pickle\n","import numpy as np\n","import time\n","import datetime\n","import random\n","import torch\n","import torch.nn as nn"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"quKITBFalxqo","executionInfo":{"status":"ok","timestamp":1615900034964,"user_tz":240,"elapsed":5577,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}}},"source":["import sys\r\n","sys.path.append(\"input-marginalization\")\r\n","\r\n","from utils import generate_dataloaders, train, test\r\n","from models import CNN"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"0qxZMqGNKni8","executionInfo":{"status":"ok","timestamp":1615900052633,"user_tz":240,"elapsed":6806,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}}},"source":["%%capture\n","try:\n","    from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup\n","except ModuleNotFoundError:\n","    !pip install transformers\n","    from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup\n","    "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tnpwoarJjKwR","executionInfo":{"status":"ok","timestamp":1615900079286,"user_tz":240,"elapsed":586,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}},"outputId":"cf0038ba-c50d-4f63-f038-49a209cbefb4"},"source":["LEARNING_RATE = 1e-4\r\n","ADAMW_TOLERANCE = 1e-8\r\n","BATCH_SIZE = 10\r\n","EPOCHS = 30\r\n","\r\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n","print(\"Running on '%s'.\" % device)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Running on 'cuda'.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZElNobPHeTq","executionInfo":{"status":"ok","timestamp":1615900083070,"user_tz":240,"elapsed":219,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}},"outputId":"07022a43-1752-45e6-b274-7b3b28ec7c90"},"source":["train_dataloader, validation_dataloader, test_dataloader = generate_dataloaders(BATCH_SIZE)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["6,919 training samples.\n","  876 validation samples.\n","1,822 test samples.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j8pDG7OHyq8H","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["2838ab9232384653a9814f6462aa9338","a889299762df48818c9920d797fbfadf","07dd493912cf4f7f9a4f8b70b1d153a1","d7f04a0011ef408499153e1329cc8099","79b58d6a92be4d2282dcf2e2a2be7923","ebb62285bcd440c6b3995c9f969f6bdd","938c65ebb461441d8d7a79d9da76b645","e6cb0cb2464d4b0495a50618ce71b5b1"]},"executionInfo":{"status":"ok","timestamp":1615900108084,"user_tz":240,"elapsed":366,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}},"outputId":"11eb3ed0-1c69-44e1-9565-9b3d04d3bf15"},"source":["import pickle\r\n","import torch\r\n","from transformers import BertTokenizer\r\n","\r\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2838ab9232384653a9814f6462aa9338","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gH6eB7B-mCC6","executionInfo":{"status":"ok","timestamp":1615900122816,"user_tz":240,"elapsed":10820,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}}},"source":["model = CNN(in_channels = 300, out_channels = 2, vocab_size = len(tokenizer.vocab), embedding_dim= 100).to(device)\r\n","save_filename = \"cnn_sst2\"\r\n","optimizer = AdamW(model.parameters(), lr = LEARNING_RATE, eps = ADAMW_TOLERANCE)\r\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = EPOCHS * BATCH_SIZE * len(train_dataloader))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J5XK8r6uyz5a","executionInfo":{"status":"ok","timestamp":1615900379197,"user_tz":240,"elapsed":251508,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}},"outputId":"e229361f-a813-48c4-b4f4-82e587b4a99c"},"source":["try:\r\n","    train(model, EPOCHS, train_dataloader, validation_dataloader, optimizer, scheduler, save_dir, save_filename, device)\r\n","except KeyboardInterrupt:\r\n","    print(\"Graceful Exit\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:01.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:02.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:03.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:04.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:05.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:06.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.76\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.59\n","  Validation Loss: 0.67\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:07.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.69\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.66\n","  Validation Loss: 0.64\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.65\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.65\n","  Validation Loss: 0.63\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.61\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.69\n","  Validation Loss: 0.61\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.58\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.69\n","  Validation Loss: 0.60\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.55\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.70\n","  Validation Loss: 0.58\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.52\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.71\n","  Validation Loss: 0.57\n","  Validation took: 0:00:00\n","\n","======== Epoch 8 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.48\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.71\n","  Validation Loss: 0.56\n","  Validation took: 0:00:00\n","\n","======== Epoch 9 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.46\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation Loss: 0.55\n","  Validation took: 0:00:00\n","\n","======== Epoch 10 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.42\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.73\n","  Validation Loss: 0.54\n","  Validation took: 0:00:00\n","\n","======== Epoch 11 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.40\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.73\n","  Validation Loss: 0.54\n","  Validation took: 0:00:00\n","\n","======== Epoch 12 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.38\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.73\n","  Validation Loss: 0.53\n","  Validation took: 0:00:00\n","\n","======== Epoch 13 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.36\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.53\n","  Validation took: 0:00:00\n","\n","======== Epoch 14 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.34\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation Loss: 0.53\n","  Validation took: 0:00:00\n","\n","======== Epoch 15 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.32\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.73\n","  Validation Loss: 0.52\n","  Validation took: 0:00:00\n","\n","======== Epoch 16 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.30\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.52\n","  Validation took: 0:00:00\n","\n","======== Epoch 17 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.28\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.73\n","  Validation Loss: 0.52\n","  Validation took: 0:00:00\n","\n","======== Epoch 18 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.28\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.52\n","  Validation took: 0:00:00\n","\n","======== Epoch 19 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.26\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.52\n","  Validation took: 0:00:00\n","\n","======== Epoch 20 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.24\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.53\n","  Validation took: 0:00:00\n","\n","======== Epoch 21 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.23\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.52\n","  Validation took: 0:00:00\n","\n","======== Epoch 22 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.21\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.52\n","  Validation took: 0:00:00\n","\n","======== Epoch 23 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.20\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.52\n","  Validation took: 0:00:00\n","\n","======== Epoch 24 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.20\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.53\n","  Validation took: 0:00:00\n","\n","======== Epoch 25 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.18\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.53\n","  Validation took: 0:00:00\n","\n","======== Epoch 26 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.18\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.53\n","  Validation took: 0:00:00\n","\n","======== Epoch 27 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.16\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.54\n","  Validation took: 0:00:00\n","\n","======== Epoch 28 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.15\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.73\n","  Validation Loss: 0.54\n","  Validation took: 0:00:00\n","\n","======== Epoch 29 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.15\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.55\n","  Validation took: 0:00:00\n","\n","======== Epoch 30 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:00.\n","  Batch    80  of    692.    Elapsed: 0:00:01.\n","  Batch   120  of    692.    Elapsed: 0:00:01.\n","  Batch   160  of    692.    Elapsed: 0:00:02.\n","  Batch   200  of    692.    Elapsed: 0:00:02.\n","  Batch   240  of    692.    Elapsed: 0:00:03.\n","  Batch   280  of    692.    Elapsed: 0:00:03.\n","  Batch   320  of    692.    Elapsed: 0:00:04.\n","  Batch   360  of    692.    Elapsed: 0:00:04.\n","  Batch   400  of    692.    Elapsed: 0:00:05.\n","  Batch   440  of    692.    Elapsed: 0:00:05.\n","  Batch   480  of    692.    Elapsed: 0:00:06.\n","  Batch   520  of    692.    Elapsed: 0:00:06.\n","  Batch   560  of    692.    Elapsed: 0:00:07.\n","  Batch   600  of    692.    Elapsed: 0:00:07.\n","  Batch   640  of    692.    Elapsed: 0:00:08.\n","  Batch   680  of    692.    Elapsed: 0:00:08.\n","\n","  Average training loss: 0.14\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.56\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Total training took 0:04:10 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0n9h0N4uNlcJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615900379911,"user_tz":240,"elapsed":245068,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}},"outputId":"3bc896c1-39f1-40ef-dcb1-44890e95a68f"},"source":["\r\n","test(model, test_dataloader, device, save_dir, save_filename)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["\n","Testing...\n","  Accuracy: 0.75\n","  Test Loss: 0.55\n","  Test took: 0:00:00\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AnGepX10J01m"},"source":[""],"execution_count":null,"outputs":[]}]}